{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using DBSCAN as clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"INITIAL\",\"login\",\"View_Items\",\"home\",\"logout\",\"View_Items_quantity\",\"Add_to_Cart\",\"shoppingcart\",\n",
    "          \"remove\",\"deferorder\",\"purchasecart\",\"inventory\",\"sellinventory\",\"clearcart\",\"cancelorder\",\"$\"]\n",
    "sessions = {'HZKS0-WG8pZr0eCsZlBAP5Xm': ['login',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'home',\n",
    "  'logout'],\n",
    " '5tPgZbHdK2Zp+heFBs8HsMkx': ['login',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'shoppingcart',\n",
    "  'remove',\n",
    "  'shoppingcart',\n",
    "  'remove',\n",
    "  'shoppingcart',\n",
    "  'remove',\n",
    "  'shoppingcart',\n",
    "  'remove',\n",
    "  'deferorder',\n",
    "  'home',\n",
    "  'logout'],\n",
    " 'RU2oCVNdpWEM0-2x7I5OjPbZ': ['login',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'purchasecart',\n",
    "  'home',\n",
    "  'logout'],\n",
    " 'kG4g0E5mqwRYcsQOCfj+7wG7': ['login',\n",
    "  'inventory',\n",
    "  'inventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'home',\n",
    "  'logout'],\n",
    " '8ocO6WP3QaFpBvkooS5INPwe': ['login',\n",
    "  'inventory',\n",
    "  'inventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'home',\n",
    "  'logout'],\n",
    " 'WOTZQBwSCnI+DfDQ-2cS7Mgp': ['login',\n",
    "  'inventory',\n",
    "  'inventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'home',\n",
    "  'logout'],\n",
    " 'e4bMe1HfiUlmvUMmPJU4y1B4': ['login',\n",
    "  'inventory',\n",
    "  'inventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'home',\n",
    "  'logout'],\n",
    " 'MEzDpcnm1MQ9GFGox7uP4Ep-': ['login',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'home',\n",
    "  'logout']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Makovchain & sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8x256 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 47 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transition_matrix(sessions, states):\n",
    "    markovchains = []\n",
    "    for key, value in sessions.items():\n",
    "        # labelEncoding\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(value)\n",
    "        transformed_s = le.transform(value)\n",
    "        \n",
    "        #factorize\n",
    "        factorize = pd.factorize(value)[0]\n",
    "        \n",
    "        # matrix\n",
    "        n = 1 + max(factorize)  # number of states\n",
    "        M = [[0] * n for _ in range(n)]\n",
    "\n",
    "        for (i, j) in zip(factorize, factorize[1:]):\n",
    "            M[i][j] += 1\n",
    "        \n",
    "        # now convert to probabilities:\n",
    "        for row in M:\n",
    "            s = sum(row)\n",
    "            if s > 0:\n",
    "                row[:] = [f / s for f in row]\n",
    "                \n",
    "        # print Matrix style\n",
    "        #for row in M: print(' '.join('{0:.2f}'.format(x) for x in row))\n",
    "        \n",
    "        # unique array in the right order\n",
    "        value = np.array(value)\n",
    "        _, idx = np.unique(value, return_index=True)\n",
    "        \n",
    "        df = pd.DataFrame(data = M, index=value[np.sort(idx)],\n",
    "                          columns=value[np.sort(idx)])\n",
    "\n",
    "        df_1 = pd.DataFrame(index=states, columns=states, dtype='float64')\n",
    "\n",
    "        #merge = df_1.merge(df, how='right').fillna(0).round(2).set_index(value[np.sort(idx)])\n",
    "        merge = df_1.update(df, join='left')\n",
    "        #merge = pd.merge(df_1, df, how='right').fillna(0).round(2).set_index(value[np.sort(idx)])\n",
    "        \n",
    "        \n",
    "        merge = pd.concat([pd.concat([df_1, df], axis=1, sort= False)], axis=0).fillna(0).round(2).iloc[:, :-n] \n",
    "        #merge = merge.iloc[:, :-n]        \n",
    "        \n",
    "        \n",
    "        # convert into Vector\n",
    "        merge = np.array(merge.values.flatten().tolist())\n",
    "        #print(len(merge))\n",
    "        # resize so the vectors got the same length\n",
    "        #size = 16*16\n",
    "        #merge.resize(size)\n",
    "        \n",
    "        # 2-D array \n",
    "        markovchains.append(merge)\n",
    "        \n",
    "        \n",
    "        # csr sparse matrix\n",
    "        csr = csr_matrix(markovchains)\n",
    "        #print(merge)\n",
    "        #markovchains.append(merge)\n",
    "        \n",
    "    #print(len(merge))\n",
    "    return csr\n",
    "\n",
    "m = transition_matrix(sessions, states)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 -1 -1  0  0  0  0  0]\n",
      "(array([-1,  0], dtype=int32), array([2, 6]))\n",
      "DBSCAN(algorithm='auto', eps=2, leaf_size=30, metric='euclidean',\n",
      "    metric_params=None, min_samples=2, n_jobs=None, p=None)\n"
     ]
    }
   ],
   "source": [
    "X = m\n",
    "clustering = DBSCAN(eps=2, min_samples=2).fit(X)\n",
    "labels = clustering.labels_\n",
    "print(labels)\n",
    "print(np.unique(labels, return_counts=True))\n",
    "print(clustering)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test\n",
    "X = np.arange(100).reshape(20,5)\n",
    "clustering = DBSCAN(eps=3, min_samples=2).fit(X)\n",
    "labels = clustering.labels_M\n",
    "print(labels)\n",
    "print(clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "Testing DBSCAN with random data + plot"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X = np.array([[1, 2], [2, 2], [2, 3],\n",
    "              [8, 7], [8, 8], [25, 80]])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clustering = DBSCAN(eps=3, min_samples=2).fit(X)\n",
    "labels = clustering.labels_\n",
    "print(clustering.labels_)\n",
    "\n",
    "clustering "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "core_samples = np.zeros_like(labels, dtype = bool)\n",
    "core_samples[clustering.core_sample_indices_] = True\n",
    "\n",
    "unique_labels = set(labels)\n",
    "plt.figure(figsize=(10, 10))\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = 'k'\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "            markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "            markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters:')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
